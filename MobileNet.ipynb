{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why a tiny model ?\n",
    "For several real time applications that require the model to run local and every second, The accurate resnet architectures fail ! because they are very large models \n",
    "\n",
    "\n",
    "# Step 1 -> Load needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 17:01:07.036217: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-24 17:01:07.414609: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-24 17:01:21.477838: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/rparchiev/.local/lib/python3.10/site-packages/cv2/../../lib64::/usr/local/lib:/usr/local/cuda/lib64:/home/rparchiev/miniconda3/lib/\n",
      "2023-03-24 17:01:21.485204: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/rparchiev/.local/lib/python3.10/site-packages/cv2/../../lib64::/usr/local/lib:/usr/local/cuda/lib64:/home/rparchiev/miniconda3/lib/\n",
      "2023-03-24 17:01:21.485256: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "# for working with files \n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import itertools  \n",
    "from tqdm import tqdm\n",
    "\n",
    "# for working with images\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import transform\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import scipy.io\n",
    "import random\n",
    "\n",
    "# tensorflow stuff\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Activation, Dropout, BatchNormalization, GlobalAveragePooling2D, Add\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import regularizers, optimizers, Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.activations import relu, softmax\n",
    "\n",
    "\n",
    "\n",
    "# for evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 -> Image preprocessing\n",
    "## 1. New directories\n",
    "Make new directories to store the preprocessed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/rparchiev/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /home/rparchiev/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /home/rparchiev/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "!mkdir car_data_cropped/\n",
    "!mkdir car_data_cropped/train\n",
    "!mkdir car_data_cropped/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Crop the images in the training folder\n",
    "Thanks to Stanford, they provide crop dimensions for the car in each photo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 8144/8144 [02:47<00:00, 48.72it/s]\n"
     ]
    }
   ],
   "source": [
    "cars_annos = pd.read_csv('train_dataset_denseNet/anno_train.csv',header=None)\n",
    "fnames = []\n",
    "class_ids = []\n",
    "bboxes = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for i in range(len(cars_annos)):\n",
    "    annotation = cars_annos.iloc[i]\n",
    "    bbox_x1 = annotation[1]\n",
    "    bbox_y1 = annotation[2]\n",
    "    bbox_x2 = annotation[3]\n",
    "    bbox_y2 = annotation[4]\n",
    "    class_id = annotation[5]\n",
    "    labels.append('%04d' % (class_id,))\n",
    "    fname = annotation[0]\n",
    "    bboxes.append((bbox_x1, bbox_y1, bbox_x2, bbox_y2))\n",
    "    class_ids.append(class_id)\n",
    "    fnames.append(fname)\n",
    "\n",
    "\n",
    "l = glob.glob('train_dataset_denseNet/car_data/car_data/train/*/*')\n",
    "\n",
    "for j in tqdm(range(len(l))):\n",
    "    i = fnames.index(l[j].split('/')[-1])\n",
    "    labels[i]\n",
    "    (x1, y1, x2, y2) = bboxes[i]\n",
    "    fname=l[j].split('/')[-1]\n",
    "    class_name = l[j].split('/')[-2]\n",
    "    src_path = os.path.join('train_dataset_denseNet/car_data/car_data/train/'+class_name+'/', fname)\n",
    "    src_image = cv.imread(src_path)\n",
    "\n",
    "    height, width = src_image.shape[:2]\n",
    "\n",
    "    # margins of 16 pixels\n",
    "    margin = 16\n",
    "    x1 = max(0, x1 - margin)\n",
    "    y1 = max(0, y1 - margin)\n",
    "    x2 = min(x2 + margin, width)\n",
    "    y2 = min(y2 + margin, height)\n",
    "    # print(\"{} -> {}\".format(fname, label))\n",
    "\n",
    "\n",
    "    dst_path = os.path.join('car_data_cropped/train/', class_name)\n",
    "    if not os.path.exists(dst_path):\n",
    "        os.makedirs(dst_path)\n",
    "\n",
    "\n",
    "    dst_path = os.path.join(dst_path, fname)\n",
    "\n",
    "\n",
    "    crop_image = src_image[y1:y2, x1:x2]\n",
    "    #dst_img = cv.resize(src=crop_image, dsize=(img_height, img_width))\n",
    "    cv.imwrite(dst_path, crop_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Crop the images in the test directory\n",
    "Here I will use them as validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_annos = pd.read_csv('train_dataset_denseNet/anno_test.csv',header=None)\n",
    "fnames = []\n",
    "class_ids = []\n",
    "bboxes = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "l = glob.glob('train_dataset_denseNet/car_data/car_data/test/*/*')\n",
    "\n",
    "\n",
    "for i in range(len(cars_annos)):\n",
    "    annotation = cars_annos.iloc[i]\n",
    "    bbox_x1 = annotation[1]\n",
    "    bbox_y1 = annotation[2]\n",
    "    bbox_x2 = annotation[3]\n",
    "    bbox_y2 = annotation[4]\n",
    "    class_id = annotation[5]\n",
    "    labels.append('%04d' % (class_id,))\n",
    "    fname = annotation[0]\n",
    "    bboxes.append((bbox_x1, bbox_y1, bbox_x2, bbox_y2))\n",
    "    class_ids.append(class_id)\n",
    "    fnames.append(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 8041/8041 [02:41<00:00, 49.88it/s]\n"
     ]
    }
   ],
   "source": [
    "for j in tqdm(range(len(l))):\n",
    "    i = fnames.index(l[j].split('/')[-1])\n",
    "\n",
    "    (x1, y1, x2, y2) = bboxes[i]\n",
    "    fname=l[j].split('/')[-1]\n",
    "\n",
    "    class_name = l[j].split('/')[-2]\n",
    "    src_path = os.path.join('train_dataset_denseNet/car_data/car_data/test/'+class_name+'/', fname)\n",
    "    src_image = cv.imread(src_path)\n",
    "\n",
    "    height, width = src_image.shape[:2]\n",
    "\n",
    "    # margins of 16 pixels\n",
    "    margin = 16\n",
    "    x1 = max(0, x1 - margin)\n",
    "    y1 = max(0, y1 - margin)\n",
    "    x2 = min(x2 + margin, width)\n",
    "    y2 = min(y2 + margin, height)\n",
    "    # print(\"{} -> {}\".format(fname, label))\n",
    "\n",
    "\n",
    "    dst_path = os.path.join('car_data_cropped/test/', class_name)\n",
    "    if not os.path.exists(dst_path):\n",
    "        os.makedirs(dst_path)\n",
    "\n",
    "    dst_path = os.path.join(dst_path, fname)\n",
    "\n",
    "\n",
    "    crop_image = src_image[y1:y2, x1:x2]\n",
    "    #dst_img = cv.resize(src=crop_image, dsize=(img_height, img_width))\n",
    "\n",
    "    cv.imwrite(dst_path, crop_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 -> prepare the image generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8144 images belonging to 196 classes.\n",
      "Found 8041 images belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "attempt = 1\n",
    "if attempt == 0:\n",
    "    train_datagen=ImageDataGenerator(rotation_range=20,\n",
    "                                     width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True)\n",
    "\n",
    "\n",
    "    valid_datagen=ImageDataGenerator(rotation_range=20,\n",
    "                                    zoom_range=0.15,\n",
    "                                    horizontal_flip=True)\n",
    "\n",
    "\n",
    "    train_generator=train_datagen.flow_from_directory(\n",
    "        directory=\"car_data_cropped/train/\",\n",
    "        batch_size=64,\n",
    "        seed=42,\n",
    "        target_size=(224,224))\n",
    "\n",
    "\n",
    "    valid_generator=valid_datagen.flow_from_directory(\n",
    "        directory=\"car_data_cropped/test/\",\n",
    "        batch_size=64,\n",
    "        seed=42,\n",
    "        target_size=(224,224))\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "if attempt == 1:\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "    train_datagen=ImageDataGenerator(rotation_range=15,\n",
    "                                     width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True,\n",
    "                                     preprocessing_function=preprocess_input)\n",
    "\n",
    "    valid_datagen=ImageDataGenerator(horizontal_flip=True, \n",
    "                                     preprocessing_function=preprocess_input)\n",
    "\n",
    "\n",
    "    train_generator=train_datagen.flow_from_directory(\n",
    "        directory=\"car_data_cropped/train/\",\n",
    "        batch_size=64,\n",
    "        seed=42,\n",
    "        target_size=(224,224))\n",
    "\n",
    "\n",
    "    valid_generator=valid_datagen.flow_from_directory(\n",
    "        directory=\"car_data_cropped/test/\",\n",
    "        batch_size=300,\n",
    "        seed=42,\n",
    "        target_size=(224,224))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'> Attempt 0: Build a tiny resnet from scratch </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(n_output, upscale=False):\n",
    "    # n_output: number of feature maps in the block\n",
    "    # upscale: should we use the 1x1 conv2d mapping for shortcut or not\n",
    "    \n",
    "    # keras functional api: return the function of type\n",
    "    # Tensor -> Tensor\n",
    "    \n",
    "    def f(x):\n",
    "        \n",
    "        # H_l(x):\n",
    "        # first pre-activation\n",
    "        h = BatchNormalization()(x)\n",
    "        h = Activation(relu)(h)\n",
    "        # first convolution\n",
    "        h = Conv2D(kernel_size=3, filters=n_output, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.01))(h)\n",
    "        \n",
    "        # second pre-activation\n",
    "        h = BatchNormalization()(x)\n",
    "        h = Activation(relu)(h)\n",
    "        # second convolution\n",
    "        h = Conv2D(kernel_size=3, filters=n_output, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.01))(h)\n",
    "        \n",
    "        # f(x):\n",
    "        if upscale:\n",
    "            # 1x1 conv2d\n",
    "            f = Conv2D(kernel_size=1, filters=n_output, strides=1, padding='same')(x)\n",
    "        else:\n",
    "            # identity\n",
    "            f = x\n",
    "        \n",
    "        # F_l(x) = f(x) + H_l(x):\n",
    "        return Add()([f, h])\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 17:02:35.769857: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-24 17:02:37.090643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78971 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:31:00.0, compute capability: 8.0\n",
      "2023-03-24 17:02:37.091938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78971 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:98:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    # input tensor is the 28x28 grayscale image\n",
    "    input_tensor = Input((224, 224, 3))\n",
    "\n",
    "    # first conv2d with post-activation to transform the input data to some reasonable form\n",
    "    x = Conv2D(kernel_size=3, filters=16, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.01))(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(relu)(x)\n",
    "\n",
    "    # F_1\n",
    "    x = block(16)(x)\n",
    "    # F_2\n",
    "    x = block(16)(x)\n",
    "\n",
    "    # F_3\n",
    "    # H_3 is the function from the tensor of size 28x28x16 to the the tensor of size 28x28x32\n",
    "    # and we can't add together tensors of inconsistent sizes, so we use upscale=True\n",
    "    x = block(32, upscale=True)(x)       # !!! <------- Uncomment for local evaluation\n",
    "    # F_4\n",
    "    x = block(32)(x)                     # !!! <------- Uncomment for local evaluation\n",
    "    # F_5\n",
    "    x = block(32)(x)                     # !!! <------- Uncomment for local evaluation\n",
    "\n",
    "    # F_6\n",
    "    x = block(48, upscale=True)(x)       # !!! <------- Uncomment for local evaluation\n",
    "    # F_7\n",
    "    x = block(48)(x)                     # !!! <------- Uncomment for local evaluation\n",
    "\n",
    "    # last activation of the entire network's output\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(relu)(x)\n",
    "\n",
    "    # average pooling across the channels\n",
    "    # 28x28x48 -> 1x48\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # dropout for more robust learning\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # last softmax layer\n",
    "    x = Dense(units=196, kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Activation(softmax)(x)\n",
    "    model = Model(inputs=input_tensor, outputs=x)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 224, 224, 16  448         ['input_5[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 224, 224, 16  64         ['conv2d_68[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_64[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 224, 224, 16  64         ['activation_68[0][0]']          \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_66[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 224, 224, 16  2320        ['activation_70[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 224, 224, 16  0           ['activation_68[0][0]',          \n",
      "                                )                                 'conv2d_70[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 224, 224, 16  64         ['add_28[0][0]']                 \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_68[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 224, 224, 16  2320        ['activation_72[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 224, 224, 16  0           ['add_28[0][0]',                 \n",
      "                                )                                 'conv2d_72[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 224, 224, 16  64         ['add_29[0][0]']                 \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_70[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 224, 224, 32  544         ['add_29[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 224, 224, 32  4640        ['activation_74[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 224, 224, 32  0           ['conv2d_75[0][0]',              \n",
      "                                )                                 'conv2d_74[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 224, 224, 32  128        ['add_30[0][0]']                 \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 224, 224, 32  0           ['batch_normalization_72[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 224, 224, 32  9248        ['activation_76[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 224, 224, 32  0           ['add_30[0][0]',                 \n",
      "                                )                                 'conv2d_77[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 224, 224, 32  128        ['add_31[0][0]']                 \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 224, 224, 32  0           ['batch_normalization_74[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 224, 224, 32  9248        ['activation_78[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 224, 224, 32  0           ['add_31[0][0]',                 \n",
      "                                )                                 'conv2d_79[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 224, 224, 32  128        ['add_32[0][0]']                 \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 224, 224, 32  0           ['batch_normalization_76[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 224, 224, 48  1584        ['add_32[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 224, 224, 48  13872       ['activation_80[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 224, 224, 48  0           ['conv2d_82[0][0]',              \n",
      "                                )                                 'conv2d_81[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 224, 224, 48  192        ['add_33[0][0]']                 \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 224, 224, 48  0           ['batch_normalization_78[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 224, 224, 48  20784       ['activation_82[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 224, 224, 48  0           ['add_33[0][0]',                 \n",
      "                                )                                 'conv2d_84[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 224, 224, 48  192        ['add_34[0][0]']                 \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 224, 224, 48  0           ['batch_normalization_79[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4 (Gl  (None, 48)          0           ['activation_83[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 48)           0           ['global_average_pooling2d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 196)          9604        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 196)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 75,636\n",
      "Trainable params: 75,124\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 16:06:42.318196: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\017TensorDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "INFO:tensorflow:batch_all_reduce: 40 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 40 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 16:06:53.634873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-24 16:06:55.211604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-24 16:06:58.727448: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-24 16:07:00.343747: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x55e45c0b8e10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-24 16:07:00.343782: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-03-24 16:07:00.343789: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-03-24 16:07:00.353817: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-24 16:07:00.635942: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 96s 738ms/step - loss: 6.6017 - accuracy: 0.0075 - val_loss: 5.7559 - val_accuracy: 0.0067\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 72s 721ms/step - loss: 5.4946 - accuracy: 0.0112 - val_loss: 5.4248 - val_accuracy: 0.0133\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 73s 726ms/step - loss: 5.3053 - accuracy: 0.0151 - val_loss: 5.3417 - val_accuracy: 0.0133\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 72s 719ms/step - loss: 5.2490 - accuracy: 0.0192 - val_loss: 5.2941 - val_accuracy: 0.0200\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 71s 704ms/step - loss: 5.2295 - accuracy: 0.0183 - val_loss: 5.2464 - val_accuracy: 0.0233\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 70s 698ms/step - loss: 5.2130 - accuracy: 0.0187 - val_loss: 5.2334 - val_accuracy: 0.0167\n",
      "Epoch 7/40\n",
      " 65/100 [==================>...........] - ETA: 24s - loss: 5.2015 - accuracy: 0.0199"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau('val_acc', factor=0.1, patience=1, verbose=1)\n",
    "\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=100,\n",
    "          validation_data=(x_val,y_val),\n",
    "          epochs=40,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font> Очень долго сходится, поэтому перейдем к mobilenet</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'> Attempt 2: use mobilenet</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in valid_generator:\n",
    "    x_val = x\n",
    "    y_val = y\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 224\n",
    "# Base model with MobileNetV2\n",
    "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,alpha = .5,\n",
    "                                                   include_top=False, \n",
    "                                                   weights='imagenet')\n",
    "\n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(.6)(x)\n",
    "    prediction_layer = tf.keras.layers.Dense(196, activation='softmax')(x)\n",
    "\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    model=Model(inputs=base_model.input,outputs=prediction_layer)\n",
    "\n",
    "    for layer in model.layers[:80]:\n",
    "        layer.trainable=False\n",
    "    for layer in model.layers[80:]:\n",
    "        layer.trainable=True\n",
    "    # \n",
    "\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,clipnorm=0.001)\n",
    "    def get_lr_metric(optimizer):\n",
    "        def lr(y_true, y_pred):\n",
    "            return optimizer.lr\n",
    "        return lr\n",
    "\n",
    "    lr_metric = get_lr_metric(optimizer)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy',lr_metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 17:04:41.696929: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\017TensorDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "INFO:tensorflow:batch_all_reduce: 77 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 77 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 17:05:03.904777: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-24 17:05:05.430918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-24 17:05:08.686829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-24 17:05:09.581379: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f7d8824a4a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-24 17:05:09.581410: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-03-24 17:05:09.581416: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-03-24 17:05:09.587105: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-24 17:05:09.842465: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 113s 781ms/step - loss: 5.7336 - accuracy: 0.0077 - lr: 1.0000e-04 - val_loss: 5.3532 - val_accuracy: 0.0200 - val_lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 5.3084 - accuracy: 0.0162 - lr: 1.0000e-04 - val_loss: 5.1244 - val_accuracy: 0.0467 - val_lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 80s 793ms/step - loss: 5.0361 - accuracy: 0.0346 - lr: 1.0000e-04 - val_loss: 4.8430 - val_accuracy: 0.0600 - val_lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 77s 771ms/step - loss: 4.7502 - accuracy: 0.0612 - lr: 1.0000e-04 - val_loss: 4.5534 - val_accuracy: 0.0933 - val_lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 77s 764ms/step - loss: 4.4490 - accuracy: 0.0898 - lr: 1.0000e-04 - val_loss: 4.2374 - val_accuracy: 0.1167 - val_lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 90s 896ms/step - loss: 4.1560 - accuracy: 0.1241 - lr: 1.0000e-04 - val_loss: 3.9343 - val_accuracy: 0.1700 - val_lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 90s 896ms/step - loss: 3.8805 - accuracy: 0.1673 - lr: 1.0000e-04 - val_loss: 3.6245 - val_accuracy: 0.2200 - val_lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 75s 745ms/step - loss: 3.6238 - accuracy: 0.2006 - lr: 1.0000e-04 - val_loss: 3.4485 - val_accuracy: 0.2500 - val_lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 76s 760ms/step - loss: 3.3554 - accuracy: 0.2341 - lr: 1.0000e-04 - val_loss: 3.2148 - val_accuracy: 0.2967 - val_lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 3.0775 - accuracy: 0.2887 - lr: 1.0000e-04 - val_loss: 2.9867 - val_accuracy: 0.3367 - val_lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 77s 770ms/step - loss: 2.8676 - accuracy: 0.3238 - lr: 1.0000e-04 - val_loss: 2.8523 - val_accuracy: 0.3700 - val_lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 77s 770ms/step - loss: 2.6146 - accuracy: 0.3741 - lr: 1.0000e-04 - val_loss: 2.5195 - val_accuracy: 0.4233 - val_lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 2.4436 - accuracy: 0.4068 - lr: 1.0000e-04 - val_loss: 2.2968 - val_accuracy: 0.4533 - val_lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 74s 743ms/step - loss: 2.2782 - accuracy: 0.4429 - lr: 1.0000e-04 - val_loss: 2.1848 - val_accuracy: 0.4733 - val_lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 78s 773ms/step - loss: 2.0800 - accuracy: 0.4855 - lr: 1.0000e-04 - val_loss: 2.1175 - val_accuracy: 0.4900 - val_lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 75s 747ms/step - loss: 1.9453 - accuracy: 0.5120 - lr: 1.0000e-04 - val_loss: 1.9246 - val_accuracy: 0.5533 - val_lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 77s 768ms/step - loss: 1.8164 - accuracy: 0.5419 - lr: 1.0000e-04 - val_loss: 1.7753 - val_accuracy: 0.5733 - val_lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 75s 751ms/step - loss: 1.7187 - accuracy: 0.5601 - lr: 1.0000e-04 - val_loss: 1.6393 - val_accuracy: 0.6000 - val_lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 74s 740ms/step - loss: 1.6096 - accuracy: 0.5866 - lr: 1.0000e-04 - val_loss: 1.5749 - val_accuracy: 0.6133 - val_lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 75s 744ms/step - loss: 1.4890 - accuracy: 0.6160 - lr: 1.0000e-04 - val_loss: 1.5030 - val_accuracy: 0.6133 - val_lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 75s 745ms/step - loss: 1.3907 - accuracy: 0.6425 - lr: 1.0000e-04 - val_loss: 1.4109 - val_accuracy: 0.6267 - val_lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 75s 745ms/step - loss: 1.3055 - accuracy: 0.6615 - lr: 1.0000e-04 - val_loss: 1.3940 - val_accuracy: 0.6333 - val_lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 74s 738ms/step - loss: 1.2250 - accuracy: 0.6774 - lr: 1.0000e-04 - val_loss: 1.3102 - val_accuracy: 0.6667 - val_lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 79s 792ms/step - loss: 1.1575 - accuracy: 0.6980 - lr: 1.0000e-04 - val_loss: 1.3435 - val_accuracy: 0.6633 - val_lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 76s 757ms/step - loss: 1.0952 - accuracy: 0.7133 - lr: 1.0000e-04 - val_loss: 1.3014 - val_accuracy: 0.6600 - val_lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 76s 758ms/step - loss: 1.0518 - accuracy: 0.7228 - lr: 1.0000e-04 - val_loss: 1.1813 - val_accuracy: 0.6933 - val_lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 77s 772ms/step - loss: 0.9899 - accuracy: 0.7363 - lr: 1.0000e-04 - val_loss: 1.1134 - val_accuracy: 0.7133 - val_lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 76s 755ms/step - loss: 0.9540 - accuracy: 0.7417 - lr: 1.0000e-04 - val_loss: 1.0611 - val_accuracy: 0.7333 - val_lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 75s 750ms/step - loss: 0.8862 - accuracy: 0.7602 - lr: 1.0000e-04 - val_loss: 1.0373 - val_accuracy: 0.7500 - val_lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 75s 749ms/step - loss: 0.8475 - accuracy: 0.7678 - lr: 1.0000e-04 - val_loss: 0.9712 - val_accuracy: 0.7467 - val_lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 75s 751ms/step - loss: 0.8072 - accuracy: 0.7816 - lr: 1.0000e-04 - val_loss: 0.9752 - val_accuracy: 0.7567 - val_lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 75s 751ms/step - loss: 0.7611 - accuracy: 0.7878 - lr: 1.0000e-04 - val_loss: 0.9175 - val_accuracy: 0.7667 - val_lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 76s 758ms/step - loss: 0.7497 - accuracy: 0.8001 - lr: 1.0000e-04 - val_loss: 0.9513 - val_accuracy: 0.7400 - val_lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 76s 753ms/step - loss: 0.7119 - accuracy: 0.8038 - lr: 1.0000e-04 - val_loss: 0.9280 - val_accuracy: 0.7267 - val_lr: 1.0000e-04\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 77s 767ms/step - loss: 0.6517 - accuracy: 0.8230 - lr: 1.0000e-04 - val_loss: 0.8657 - val_accuracy: 0.7667 - val_lr: 1.0000e-04\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 77s 769ms/step - loss: 0.6290 - accuracy: 0.8328 - lr: 1.0000e-04 - val_loss: 0.8339 - val_accuracy: 0.7933 - val_lr: 1.0000e-04\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.6189 - accuracy: 0.8360 - lr: 1.0000e-04 - val_loss: 0.8505 - val_accuracy: 0.7900 - val_lr: 1.0000e-04\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 81s 807ms/step - loss: 0.5962 - accuracy: 0.8377 - lr: 1.0000e-04 - val_loss: 0.8377 - val_accuracy: 0.7900 - val_lr: 1.0000e-04\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 77s 770ms/step - loss: 0.5878 - accuracy: 0.8401 - lr: 1.0000e-04 - val_loss: 0.8531 - val_accuracy: 0.7767 - val_lr: 1.0000e-04\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 75s 741ms/step - loss: 0.5463 - accuracy: 0.8522 - lr: 1.0000e-04 - val_loss: 0.7892 - val_accuracy: 0.7833 - val_lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb0742cbee0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reduce_lr = ReduceLROnPlateau('val_acc', factor=0.1, patience=1, verbose=1)\n",
    "\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=100,\n",
    "          validation_data=(x_val,y_val),\n",
    "          epochs=40,verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 -> Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_125096/754504181.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  scoreSeg = model.evaluate_generator(valid_generator)\n",
      "2023-03-24 17:57:16.218508: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021TensorDataset:875\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.7739087343215942\n",
      "(300, 224, 224, 3) (300, 196)\n",
      "10/10 [==============================] - 3s 16ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.50      1.00      0.67         1\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      0.50      0.67         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      0.50      0.67         2\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       0.33      1.00      0.50         1\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      1.00      1.00         1\n",
      "          17       1.00      0.50      0.67         2\n",
      "          18       0.67      1.00      0.80         2\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       1.00      1.00      1.00         3\n",
      "          21       0.33      0.25      0.29         4\n",
      "          22       0.20      1.00      0.33         1\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       1.00      1.00      1.00         1\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.75      0.50      0.60         6\n",
      "          31       1.00      1.00      1.00         2\n",
      "          33       0.56      1.00      0.71         5\n",
      "          34       1.00      1.00      1.00         1\n",
      "          37       1.00      0.50      0.67         2\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       1.00      0.50      0.67         4\n",
      "          40       0.00      0.00      0.00         0\n",
      "          42       1.00      0.33      0.50         3\n",
      "          43       0.33      0.50      0.40         2\n",
      "          45       1.00      1.00      1.00         1\n",
      "          46       1.00      0.50      0.67         2\n",
      "          47       1.00      1.00      1.00         3\n",
      "          48       1.00      1.00      1.00         2\n",
      "          49       1.00      1.00      1.00         3\n",
      "          50       1.00      1.00      1.00         1\n",
      "          52       1.00      0.50      0.67         2\n",
      "          55       1.00      1.00      1.00         1\n",
      "          56       0.50      1.00      0.67         1\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.33      1.00      0.50         1\n",
      "          59       0.50      0.50      0.50         2\n",
      "          61       1.00      1.00      1.00         1\n",
      "          62       1.00      0.50      0.67         4\n",
      "          63       0.50      1.00      0.67         3\n",
      "          64       0.50      0.50      0.50         2\n",
      "          65       0.67      0.67      0.67         3\n",
      "          66       1.00      1.00      1.00         1\n",
      "          67       0.33      1.00      0.50         1\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       1.00      1.00      1.00         1\n",
      "          70       1.00      0.50      0.67         2\n",
      "          71       0.67      1.00      0.80         2\n",
      "          72       1.00      1.00      1.00         1\n",
      "          73       1.00      0.75      0.86         4\n",
      "          74       1.00      0.50      0.67         2\n",
      "          75       0.67      1.00      0.80         2\n",
      "          77       1.00      1.00      1.00         3\n",
      "          79       0.00      0.00      0.00         1\n",
      "          81       1.00      0.50      0.67         6\n",
      "          82       1.00      1.00      1.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          85       1.00      1.00      1.00         1\n",
      "          86       0.50      1.00      0.67         1\n",
      "          91       1.00      1.00      1.00         1\n",
      "          92       1.00      1.00      1.00         2\n",
      "          93       0.75      0.75      0.75         4\n",
      "          94       1.00      1.00      1.00         1\n",
      "          96       1.00      0.50      0.67         2\n",
      "          97       1.00      0.67      0.80         3\n",
      "          98       1.00      1.00      1.00         1\n",
      "         100       0.67      1.00      0.80         2\n",
      "         101       0.67      0.67      0.67         3\n",
      "         102       0.67      1.00      0.80         2\n",
      "         103       1.00      0.71      0.83         7\n",
      "         104       1.00      1.00      1.00         1\n",
      "         105       1.00      1.00      1.00         2\n",
      "         106       1.00      1.00      1.00         2\n",
      "         107       1.00      1.00      1.00         5\n",
      "         108       1.00      1.00      1.00         1\n",
      "         109       1.00      1.00      1.00         2\n",
      "         110       1.00      1.00      1.00         2\n",
      "         111       0.00      0.00      0.00         0\n",
      "         113       1.00      1.00      1.00         1\n",
      "         114       0.75      1.00      0.86         3\n",
      "         115       0.00      0.00      0.00         1\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.67      0.67      0.67         3\n",
      "         119       0.60      0.75      0.67         4\n",
      "         120       0.33      1.00      0.50         1\n",
      "         121       1.00      1.00      1.00         2\n",
      "         122       1.00      1.00      1.00         3\n",
      "         123       1.00      1.00      1.00         1\n",
      "         126       1.00      0.33      0.50         3\n",
      "         127       0.75      1.00      0.86         3\n",
      "         130       0.50      1.00      0.67         1\n",
      "         131       1.00      1.00      1.00         1\n",
      "         132       1.00      1.00      1.00         2\n",
      "         133       1.00      1.00      1.00         1\n",
      "         135       1.00      1.00      1.00         1\n",
      "         137       1.00      0.67      0.80         3\n",
      "         138       1.00      1.00      1.00         4\n",
      "         139       0.67      1.00      0.80         2\n",
      "         140       1.00      0.67      0.80         3\n",
      "         141       1.00      1.00      1.00         2\n",
      "         143       1.00      1.00      1.00         3\n",
      "         145       1.00      0.33      0.50         3\n",
      "         146       0.00      0.00      0.00         1\n",
      "         147       0.67      0.67      0.67         3\n",
      "         148       1.00      0.50      0.67         2\n",
      "         149       1.00      1.00      1.00         1\n",
      "         150       0.67      1.00      0.80         2\n",
      "         151       1.00      1.00      1.00         2\n",
      "         152       0.50      1.00      0.67         1\n",
      "         153       0.00      0.00      0.00         2\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       1.00      1.00      1.00         1\n",
      "         157       0.33      0.50      0.40         2\n",
      "         159       1.00      1.00      1.00         2\n",
      "         160       0.60      1.00      0.75         3\n",
      "         161       0.50      1.00      0.67         1\n",
      "         162       1.00      0.50      0.67         2\n",
      "         163       0.20      0.50      0.29         2\n",
      "         164       1.00      1.00      1.00         1\n",
      "         165       0.50      1.00      0.67         1\n",
      "         167       1.00      1.00      1.00         2\n",
      "         168       1.00      1.00      1.00         2\n",
      "         169       1.00      1.00      1.00         1\n",
      "         171       0.50      0.50      0.50         2\n",
      "         172       1.00      1.00      1.00         1\n",
      "         173       1.00      0.75      0.86         4\n",
      "         174       0.50      1.00      0.67         2\n",
      "         175       1.00      0.67      0.80         3\n",
      "         176       1.00      0.75      0.86         4\n",
      "         177       1.00      1.00      1.00         3\n",
      "         181       1.00      1.00      1.00         2\n",
      "         183       0.50      1.00      0.67         1\n",
      "         186       1.00      0.50      0.67         2\n",
      "         188       1.00      1.00      1.00         2\n",
      "         189       0.00      0.00      0.00         0\n",
      "         190       1.00      0.50      0.67         2\n",
      "         192       0.50      1.00      0.67         3\n",
      "         194       1.00      1.00      1.00         2\n",
      "         195       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.75       300\n",
      "   macro avg       0.73      0.73      0.70       300\n",
      "weighted avg       0.80      0.75      0.74       300\n",
      "\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 3 0 0]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rparchiev/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rparchiev/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rparchiev/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rparchiev/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rparchiev/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rparchiev/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "scoreSeg = model.evaluate_generator(valid_generator)\n",
    "print(\"Accuracy = \",scoreSeg[1])\n",
    "\n",
    "for i,j in valid_generator:\n",
    "    print(i.shape, j.shape)\n",
    "    p = model.predict(i)\n",
    "    p = p.argmax(-1)\n",
    "    t = j.argmax(-1)\n",
    "    print(classification_report(t,p))\n",
    "    print(confusion_matrix(t,p))\n",
    "    break;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 22,  33, 106, 160,  33, 138, 173,  29, 111,  92,  18, 165,  49,\n",
       "       174,  77, 150, 177,  97,  47,  73, 107,  63, 137, 143,  64, 102,\n",
       "       181, 172, 122,   2, 148,  58,   8,  13, 171, 132,  22, 152,  81,\n",
       "        66,  16,   1, 127,  52, 143, 110,  65, 141, 192, 127,  13, 165,\n",
       "        71, 101,  59, 160,  58,   2, 192,  34, 159,  49,  43, 190, 103,\n",
       "        47, 103, 109, 104,  61, 161, 119, 114, 176,  73, 149, 147, 195,\n",
       "       119,  13,  22,  58,   8, 195,  21,  63, 174,  96, 176,  92, 156,\n",
       "        10, 145,   3, 147, 154,  33,   0,  81, 133, 164, 101, 110, 194,\n",
       "        91, 151,  33, 174,  63, 150, 160, 169, 152, 138, 168, 119,  71,\n",
       "        20, 107, 121, 114, 162,  33,  93,   3,  46, 157,  18,  94, 138,\n",
       "        67,  63,  50, 109, 141,  33, 140, 194,  75,  65,  56, 103,  48,\n",
       "       177, 103, 150, 103,  85, 131, 160, 107,  55,  77,  22,  29,  49,\n",
       "        27, 100, 192, 173,  48, 126, 127,  74, 163, 154,  47,  67, 146,\n",
       "       192, 161, 176, 101,  56, 177,  43, 192,  26,  11,  39, 157, 189,\n",
       "        64, 173, 160, 192, 163, 130,  20,  81,  15,  21, 105, 171, 121,\n",
       "       139,  69, 120,  75, 107,  33, 155, 183, 100, 119, 174, 159, 114,\n",
       "        31, 123,  97,  31,  11,  14,   6,  82,  73,  62,  63, 157,  40,\n",
       "       183,  72,  98, 139,  77,  17,   5,  45, 102,  33, 167, 102, 118,\n",
       "       122, 147,  93,  75,  11, 118,  18, 108,   7,  71,  22, 139,  29,\n",
       "       175, 138, 107, 181,  70,  43, 137, 127, 195, 168, 120, 188, 118,\n",
       "       120, 122, 130,  59, 100, 119, 186,  86, 163,   9, 105,  42,  93,\n",
       "       140,  21, 163, 175,  63,  37,  39, 114, 113,  62,   0, 163, 151,\n",
       "       132,  15, 135, 188,  20,  67,  29, 106,  33, 143, 167,  86,  65,\n",
       "        93])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'AM General Hummer SUV 2000',\n",
       " 1: 'Acura Integra Type R 2001',\n",
       " 2: 'Acura RL Sedan 2012',\n",
       " 3: 'Acura TL Sedan 2012',\n",
       " 4: 'Acura TL Type-S 2008',\n",
       " 5: 'Acura TSX Sedan 2012',\n",
       " 6: 'Acura ZDX Hatchback 2012',\n",
       " 7: 'Aston Martin V8 Vantage Convertible 2012',\n",
       " 8: 'Aston Martin V8 Vantage Coupe 2012',\n",
       " 9: 'Aston Martin Virage Convertible 2012',\n",
       " 10: 'Aston Martin Virage Coupe 2012',\n",
       " 11: 'Audi 100 Sedan 1994',\n",
       " 12: 'Audi 100 Wagon 1994',\n",
       " 13: 'Audi A5 Coupe 2012',\n",
       " 14: 'Audi R8 Coupe 2012',\n",
       " 15: 'Audi RS 4 Convertible 2008',\n",
       " 16: 'Audi S4 Sedan 2007',\n",
       " 17: 'Audi S4 Sedan 2012',\n",
       " 18: 'Audi S5 Convertible 2012',\n",
       " 19: 'Audi S5 Coupe 2012',\n",
       " 20: 'Audi S6 Sedan 2011',\n",
       " 21: 'Audi TT Hatchback 2011',\n",
       " 22: 'Audi TT RS Coupe 2012',\n",
       " 23: 'Audi TTS Coupe 2012',\n",
       " 24: 'Audi V8 Sedan 1994',\n",
       " 25: 'BMW 1 Series Convertible 2012',\n",
       " 26: 'BMW 1 Series Coupe 2012',\n",
       " 27: 'BMW 3 Series Sedan 2012',\n",
       " 28: 'BMW 3 Series Wagon 2012',\n",
       " 29: 'BMW 6 Series Convertible 2007',\n",
       " 30: 'BMW ActiveHybrid 5 Sedan 2012',\n",
       " 31: 'BMW M3 Coupe 2012',\n",
       " 32: 'BMW M5 Sedan 2010',\n",
       " 33: 'BMW M6 Convertible 2010',\n",
       " 34: 'BMW X3 SUV 2012',\n",
       " 35: 'BMW X5 SUV 2007',\n",
       " 36: 'BMW X6 SUV 2012',\n",
       " 37: 'BMW Z4 Convertible 2012',\n",
       " 38: 'Bentley Arnage Sedan 2009',\n",
       " 39: 'Bentley Continental Flying Spur Sedan 2007',\n",
       " 40: 'Bentley Continental GT Coupe 2007',\n",
       " 41: 'Bentley Continental GT Coupe 2012',\n",
       " 42: 'Bentley Continental Supersports Conv. Convertible 2012',\n",
       " 43: 'Bentley Mulsanne Sedan 2011',\n",
       " 44: 'Bugatti Veyron 16.4 Convertible 2009',\n",
       " 45: 'Bugatti Veyron 16.4 Coupe 2009',\n",
       " 46: 'Buick Enclave SUV 2012',\n",
       " 47: 'Buick Rainier SUV 2007',\n",
       " 48: 'Buick Regal GS 2012',\n",
       " 49: 'Buick Verano Sedan 2012',\n",
       " 50: 'Cadillac CTS-V Sedan 2012',\n",
       " 51: 'Cadillac Escalade EXT Crew Cab 2007',\n",
       " 52: 'Cadillac SRX SUV 2012',\n",
       " 53: 'Chevrolet Avalanche Crew Cab 2012',\n",
       " 54: 'Chevrolet Camaro Convertible 2012',\n",
       " 55: 'Chevrolet Cobalt SS 2010',\n",
       " 56: 'Chevrolet Corvette Convertible 2012',\n",
       " 57: 'Chevrolet Corvette Ron Fellows Edition Z06 2007',\n",
       " 58: 'Chevrolet Corvette ZR1 2012',\n",
       " 59: 'Chevrolet Express Cargo Van 2007',\n",
       " 60: 'Chevrolet Express Van 2007',\n",
       " 61: 'Chevrolet HHR SS 2010',\n",
       " 62: 'Chevrolet Impala Sedan 2007',\n",
       " 63: 'Chevrolet Malibu Hybrid Sedan 2010',\n",
       " 64: 'Chevrolet Malibu Sedan 2007',\n",
       " 65: 'Chevrolet Monte Carlo Coupe 2007',\n",
       " 66: 'Chevrolet Silverado 1500 Classic Extended Cab 2007',\n",
       " 67: 'Chevrolet Silverado 1500 Extended Cab 2012',\n",
       " 68: 'Chevrolet Silverado 1500 Hybrid Crew Cab 2012',\n",
       " 69: 'Chevrolet Silverado 1500 Regular Cab 2012',\n",
       " 70: 'Chevrolet Silverado 2500HD Regular Cab 2012',\n",
       " 71: 'Chevrolet Sonic Sedan 2012',\n",
       " 72: 'Chevrolet Tahoe Hybrid SUV 2012',\n",
       " 73: 'Chevrolet TrailBlazer SS 2009',\n",
       " 74: 'Chevrolet Traverse SUV 2012',\n",
       " 75: 'Chrysler 300 SRT-8 2010',\n",
       " 76: 'Chrysler Aspen SUV 2009',\n",
       " 77: 'Chrysler Crossfire Convertible 2008',\n",
       " 78: 'Chrysler PT Cruiser Convertible 2008',\n",
       " 79: 'Chrysler Sebring Convertible 2010',\n",
       " 80: 'Chrysler Town and Country Minivan 2012',\n",
       " 81: 'Daewoo Nubira Wagon 2002',\n",
       " 82: 'Dodge Caliber Wagon 2007',\n",
       " 83: 'Dodge Caliber Wagon 2012',\n",
       " 84: 'Dodge Caravan Minivan 1997',\n",
       " 85: 'Dodge Challenger SRT8 2011',\n",
       " 86: 'Dodge Charger SRT-8 2009',\n",
       " 87: 'Dodge Charger Sedan 2012',\n",
       " 88: 'Dodge Dakota Club Cab 2007',\n",
       " 89: 'Dodge Dakota Crew Cab 2010',\n",
       " 90: 'Dodge Durango SUV 2007',\n",
       " 91: 'Dodge Durango SUV 2012',\n",
       " 92: 'Dodge Journey SUV 2012',\n",
       " 93: 'Dodge Magnum Wagon 2008',\n",
       " 94: 'Dodge Ram Pickup 3500 Crew Cab 2010',\n",
       " 95: 'Dodge Ram Pickup 3500 Quad Cab 2009',\n",
       " 96: 'Dodge Sprinter Cargo Van 2009',\n",
       " 97: 'Eagle Talon Hatchback 1998',\n",
       " 98: 'FIAT 500 Abarth 2012',\n",
       " 99: 'FIAT 500 Convertible 2012',\n",
       " 100: 'Ferrari 458 Italia Convertible 2012',\n",
       " 101: 'Ferrari 458 Italia Coupe 2012',\n",
       " 102: 'Ferrari California Convertible 2012',\n",
       " 103: 'Ferrari FF Coupe 2012',\n",
       " 104: 'Fisker Karma Sedan 2012',\n",
       " 105: 'Ford E-Series Wagon Van 2012',\n",
       " 106: 'Ford Edge SUV 2012',\n",
       " 107: 'Ford Expedition EL SUV 2009',\n",
       " 108: 'Ford F-150 Regular Cab 2007',\n",
       " 109: 'Ford F-150 Regular Cab 2012',\n",
       " 110: 'Ford F-450 Super Duty Crew Cab 2012',\n",
       " 111: 'Ford Fiesta Sedan 2012',\n",
       " 112: 'Ford Focus Sedan 2007',\n",
       " 113: 'Ford Freestar Minivan 2007',\n",
       " 114: 'Ford GT Coupe 2006',\n",
       " 115: 'Ford Mustang Convertible 2007',\n",
       " 116: 'Ford Ranger SuperCab 2011',\n",
       " 117: 'GMC Acadia SUV 2012',\n",
       " 118: 'GMC Canyon Extended Cab 2012',\n",
       " 119: 'GMC Savana Van 2012',\n",
       " 120: 'GMC Terrain SUV 2012',\n",
       " 121: 'GMC Yukon Hybrid SUV 2012',\n",
       " 122: 'Geo Metro Convertible 1993',\n",
       " 123: 'HUMMER H2 SUT Crew Cab 2009',\n",
       " 124: 'HUMMER H3T Crew Cab 2010',\n",
       " 125: 'Honda Accord Coupe 2012',\n",
       " 126: 'Honda Accord Sedan 2012',\n",
       " 127: 'Honda Odyssey Minivan 2007',\n",
       " 128: 'Honda Odyssey Minivan 2012',\n",
       " 129: 'Hyundai Accent Sedan 2012',\n",
       " 130: 'Hyundai Azera Sedan 2012',\n",
       " 131: 'Hyundai Elantra Sedan 2007',\n",
       " 132: 'Hyundai Elantra Touring Hatchback 2012',\n",
       " 133: 'Hyundai Genesis Sedan 2012',\n",
       " 134: 'Hyundai Santa Fe SUV 2012',\n",
       " 135: 'Hyundai Sonata Hybrid Sedan 2012',\n",
       " 136: 'Hyundai Sonata Sedan 2012',\n",
       " 137: 'Hyundai Tucson SUV 2012',\n",
       " 138: 'Hyundai Veloster Hatchback 2012',\n",
       " 139: 'Hyundai Veracruz SUV 2012',\n",
       " 140: 'Infiniti G Coupe IPL 2012',\n",
       " 141: 'Infiniti QX56 SUV 2011',\n",
       " 142: 'Isuzu Ascender SUV 2008',\n",
       " 143: 'Jaguar XK XKR 2012',\n",
       " 144: 'Jeep Compass SUV 2012',\n",
       " 145: 'Jeep Grand Cherokee SUV 2012',\n",
       " 146: 'Jeep Liberty SUV 2012',\n",
       " 147: 'Jeep Patriot SUV 2012',\n",
       " 148: 'Jeep Wrangler SUV 2012',\n",
       " 149: 'Lamborghini Aventador Coupe 2012',\n",
       " 150: 'Lamborghini Diablo Coupe 2001',\n",
       " 151: 'Lamborghini Gallardo LP 570-4 Superleggera 2012',\n",
       " 152: 'Lamborghini Reventon Coupe 2008',\n",
       " 153: 'Land Rover LR2 SUV 2012',\n",
       " 154: 'Land Rover Range Rover SUV 2012',\n",
       " 155: 'Lincoln Town Car Sedan 2011',\n",
       " 156: 'MINI Cooper Roadster Convertible 2012',\n",
       " 157: 'Maybach Landaulet Convertible 2012',\n",
       " 158: 'Mazda Tribute SUV 2011',\n",
       " 159: 'McLaren MP4-12C Coupe 2012',\n",
       " 160: 'Mercedes-Benz 300-Class Convertible 1993',\n",
       " 161: 'Mercedes-Benz C-Class Sedan 2012',\n",
       " 162: 'Mercedes-Benz E-Class Sedan 2012',\n",
       " 163: 'Mercedes-Benz S-Class Sedan 2012',\n",
       " 164: 'Mercedes-Benz SL-Class Coupe 2009',\n",
       " 165: 'Mercedes-Benz Sprinter Van 2012',\n",
       " 166: 'Mitsubishi Lancer Sedan 2012',\n",
       " 167: 'Nissan 240SX Coupe 1998',\n",
       " 168: 'Nissan Juke Hatchback 2012',\n",
       " 169: 'Nissan Leaf Hatchback 2012',\n",
       " 170: 'Nissan NV Passenger Van 2012',\n",
       " 171: 'Plymouth Neon Coupe 1999',\n",
       " 172: 'Porsche Panamera Sedan 2012',\n",
       " 173: 'Ram C-V Cargo Van Minivan 2012',\n",
       " 174: 'Rolls-Royce Ghost Sedan 2012',\n",
       " 175: 'Rolls-Royce Phantom Drophead Coupe Convertible 2012',\n",
       " 176: 'Rolls-Royce Phantom Sedan 2012',\n",
       " 177: 'Scion xD Hatchback 2012',\n",
       " 178: 'Spyker C8 Convertible 2009',\n",
       " 179: 'Spyker C8 Coupe 2009',\n",
       " 180: 'Suzuki Aerio Sedan 2007',\n",
       " 181: 'Suzuki Kizashi Sedan 2012',\n",
       " 182: 'Suzuki SX4 Hatchback 2012',\n",
       " 183: 'Suzuki SX4 Sedan 2012',\n",
       " 184: 'Tesla Model S Sedan 2012',\n",
       " 185: 'Toyota 4Runner SUV 2012',\n",
       " 186: 'Toyota Camry Sedan 2012',\n",
       " 187: 'Toyota Corolla Sedan 2012',\n",
       " 188: 'Toyota Sequoia SUV 2012',\n",
       " 189: 'Volkswagen Beetle Hatchback 2012',\n",
       " 190: 'Volkswagen Golf Hatchback 1991',\n",
       " 191: 'Volkswagen Golf Hatchback 2012',\n",
       " 192: 'Volvo 240 Sedan 1993',\n",
       " 193: 'Volvo C30 Hatchback 2012',\n",
       " 194: 'Volvo XC90 SUV 2007',\n",
       " 195: 'smart fortwo Convertible 2012'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i:j for j,i in valid_generator.class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21,  29, 106,  25,  33, 138, 173,  29, 137,  92,  18,  96,  49,\n",
       "       176,  77, 150, 177,  97,  47,  73, 107,  65, 137, 143,  62, 103,\n",
       "       181, 172, 122,   2, 148,  57,   8,  28, 171, 132,  21, 152,  81,\n",
       "        66,  16, 171, 127,  52, 143, 110,  65, 141, 190, 127,  19, 165,\n",
       "       126, 101, 119, 160,  58, 126, 192,  34, 159,  49,  38, 190, 103,\n",
       "        47, 103, 109, 104,  61, 161,  59, 114, 176,  73, 149, 146, 195,\n",
       "        81,  13,  21,   7,   8, 195,  23,  62, 174,  96, 176,  92, 156,\n",
       "        10, 145,   3, 147, 153,  33,   0,  81, 133, 164, 103, 110, 194,\n",
       "        91, 151,   9,   4,  39, 150, 115, 169, 157, 138, 168, 119,  71,\n",
       "        20, 107, 121, 114, 162,  33,  81,   3,  46, 157,  18,  94, 138,\n",
       "       118,  63,  50, 109, 141,  33, 140, 194,  75,  97, 175, 103,  48,\n",
       "       177, 103,   1, 103,  85, 131, 160, 107,  55,  77,  19,  29,  49,\n",
       "        27, 100, 147, 173,  48, 126, 173,  74, 163, 153,  47,  68, 145,\n",
       "       192, 163, 176, 101,  56, 177,  43, 192,  26,  12,  39,  43,  42,\n",
       "        64, 173, 160, 154, 140, 130,  20,  81,  15,  21, 105,  81, 121,\n",
       "       139,  69, 120,  75, 107,  29,  79,  74, 100, 119, 174, 159, 148,\n",
       "        31, 123,  97,  31,  24,  14,   6,  82,  73,  62,  63,  42,  39,\n",
       "       183,  72,  98,  46,  77,  17,   5,  45, 102,  33, 167, 102, 118,\n",
       "       122, 147,  93,  93,  12, 118,  17, 108,   7,  71,  22, 139,  29,\n",
       "       175, 138, 107, 181,  70, 117, 137, 127, 195, 168,  52, 188,  70,\n",
       "       145, 122, 186,  59, 101, 119, 186,  86, 162,   9, 105,  42,  93,\n",
       "       140,  23,  64, 175,  63,  37,  39, 114, 113,  62,   0,  83, 151,\n",
       "       132,  15, 135, 188,  20,  67,  37, 106,  29, 143, 167,  73,  65,\n",
       "        93])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    \"cars1_half.h5\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 /196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('cars1_half2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/MobileNet_77acc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/MobileNet_77acc/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_models/MobileNet_77acc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
